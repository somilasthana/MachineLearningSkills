{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Application-Churn-Prediction-Telecom-Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somilasthana/MachineLearningSkills/blob/master/Application_Churn_Prediction_Telecom_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QUqBdKA5BVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir telco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGMdMgJWfOGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1d10bde7-cf5c-4b1c-93b3-26615e6d1d93"
      },
      "source": [
        "!unzip /content/telco/telco-customer-churn.zip # Get it from Kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/telco/telco-customer-churn.zip\n",
            "  inflating: WA_Fn-UseC_-Telco-Customer-Churn.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE9xhWVmg16Z",
        "colab_type": "text"
      },
      "source": [
        "#Data Details\n",
        "\n",
        "The raw data contains 7043 rows (customers) and 21 columns (features).\n",
        "\n",
        "Each row represents a customer, each column contains customer’s attributes described on the column Metadata.\n",
        "\n",
        "* Customers who left within the last month – the column is called Churn\n",
        "\n",
        "* Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
        "\n",
        "* Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
        "\n",
        "* Demographic info about customers – gender, age range, and if they have partners and dependents\n",
        "\n",
        "Description of fields\n",
        "\n",
        "* customerID: Customer ID\n",
        "\n",
        "* gender: Male or Female\n",
        "\n",
        "* SeniorCitizen: 0 or 1\n",
        "\n",
        "* Partner: whether partner 0 or 1\n",
        "\n",
        "* Dependents:  have dependent or not ( Yes or No )\n",
        "\n",
        "* tenure: number of months the customer stayed with the company.\n",
        "\n",
        "* PhoneService: phone service used ( Yes or No )\n",
        "\n",
        "* MultipleLines: Customer has multiple lines or not (Yes, No, No phone service)\n",
        "\n",
        "* InternetService: Customer’s internet service provider (DSL, Fiber optic, No)\n",
        "\n",
        "* OnlineSecurity: Customer has online security or not (Yes, No, No internet service)\n",
        "\n",
        "* OnlineBackup: Customer has online backup or not (Yes, No, No internet service)\n",
        "\n",
        "* DeviceProtection: Customer has device protection or not (Yes, No, No internet service)\n",
        "\n",
        "* TechSupport: Customer has tech support or not (Yes, No, No internet service)\n",
        "\n",
        "* Streaming: TV: Customer has streaming TV or not (Yes, No, No internet service)\n",
        "\n",
        "* StreamingMovies: Customer has streaming movies or not (Yes, No, No internet service)\n",
        "\n",
        "* Contract: Contract term of the customer (Month-to-month, One year, Two year)\n",
        "\n",
        "* PaperlessBilling: Yes or No\n",
        "\n",
        "* PaymentMethod: Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)\n",
        "\n",
        "* MonthlyCharges: Amount charged \n",
        "\n",
        "* TotalCharges:  Total amount charged to the customer\n",
        "\n",
        "* Churn:  Yes or No"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uswh8Q1elzN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glhV_Gjalmts",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mk0e6kclkbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_df = pd.read_csv(\"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyF3MQC5mGc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "568d9ca8-f800-4601-8ec8-b21804cb7fca"
      },
      "source": [
        "churn_df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen  ... MonthlyCharges TotalCharges  Churn\n",
              "0  7590-VHVEG  Female              0  ...          29.85        29.85     No\n",
              "1  5575-GNVDE    Male              0  ...          56.95       1889.5     No\n",
              "2  3668-QPYBK    Male              0  ...          53.85       108.15    Yes\n",
              "3  7795-CFOCW    Male              0  ...          42.30      1840.75     No\n",
              "4  9237-HQITU  Female              0  ...          70.70       151.65    Yes\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY_ghWZfmKXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d3228bb-8b05-4bf3-e860-64bef6c72290"
      },
      "source": [
        "print(\"Shape=\",churn_df.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape= (7043, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YptWUj-YmcNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "42575237-2c76-4e16-ef60-5e447bbf0fb1"
      },
      "source": [
        "churn_df.isna().any()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID          False\n",
              "gender              False\n",
              "SeniorCitizen       False\n",
              "Partner             False\n",
              "Dependents          False\n",
              "tenure              False\n",
              "PhoneService        False\n",
              "MultipleLines       False\n",
              "InternetService     False\n",
              "OnlineSecurity      False\n",
              "OnlineBackup        False\n",
              "DeviceProtection    False\n",
              "TechSupport         False\n",
              "StreamingTV         False\n",
              "StreamingMovies     False\n",
              "Contract            False\n",
              "PaperlessBilling    False\n",
              "PaymentMethod       False\n",
              "MonthlyCharges      False\n",
              "TotalCharges        False\n",
              "Churn               False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCFJW76QBBLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "cf0c67c9-9f7e-4b9a-f811-fc9f50f22f48"
      },
      "source": [
        "churn_df.dtypes"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID           object\n",
              "gender               object\n",
              "SeniorCitizen         int64\n",
              "Partner              object\n",
              "Dependents           object\n",
              "tenure                int64\n",
              "PhoneService         object\n",
              "MultipleLines        object\n",
              "InternetService      object\n",
              "OnlineSecurity       object\n",
              "OnlineBackup         object\n",
              "DeviceProtection     object\n",
              "TechSupport          object\n",
              "StreamingTV          object\n",
              "StreamingMovies      object\n",
              "Contract             object\n",
              "PaperlessBilling     object\n",
              "PaymentMethod        object\n",
              "MonthlyCharges      float64\n",
              "TotalCharges         object\n",
              "Churn                object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9TEMDpeGPHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_df[\"TotalCharges\"] = churn_df[\"TotalCharges\"].apply(lambda x: float(x.strip()) if len(x.strip()) != 0 else 0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH2C1zs1m6Rr",
        "colab_type": "text"
      },
      "source": [
        "#Plan of Action\n",
        "\n",
        "1. First Split the data using StraifiedKFold into 5 splits, repetition allowed.\n",
        "2. Build Initial Machine Learning Framework ( also include Customer ID ): Algorithms used KNN, SVM, RandomForest, ExtraTreeForest, XGB ( the results are not good enough )\n",
        "2. Stack Feaures ( Not Models ) Transform the data using PCA, NCA, SelectKBest, LDA, SelectKModel\n",
        "3. Build the second Machine Learning Framework: Algorithms used KNN, SVM, RandomForest, ExtraTreeForest, XGB ( the results are not good enough )\n",
        "4. Stack Features again but using Count Encoder, Percentile Encoder, Likelihood Encoder ( given by ) Far0n/kaggletils\n",
        "5. Build the second Machine Learning Framework: Algorithms used KNN, SVM, RandomForest,, XGB). RandomForest is giving promising results\n",
        "6. Grid Search to find best parameters for  RandomForest ( by running on one 1 fold data )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1KRQRrqOlza",
        "colab_type": "text"
      },
      "source": [
        "## StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vphg2OC5frul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = churn_df.values[:, :-1]\n",
        "y = churn_df.values[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ22WeauKbIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "55d453b6-24b5-45c9-c27f-785ec7e038d3"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['7590-VHVEG', 'Female', 0, 'Yes', 'No', 1, 'No',\n",
              "       'No phone service', 'DSL', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
              "       'Month-to-month', 'Yes', 'Electronic check', 29.85, 29.85],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQHqRVplOpop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RepeatStratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "rksf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
        "training_test_split = []\n",
        "for train_index, test_index in rksf.split(X, y):\n",
        "  training_test_split.append((train_index, test_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE-LyS5Z3Nd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8922eb7-0a83-463b-d1dc-a35787b471b5"
      },
      "source": [
        "len(training_test_split[0][0]), len(training_test_split[0][1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5634, 1409)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwHI4tdDlYE2",
        "colab_type": "text"
      },
      "source": [
        "## The Machine Learning Framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0m7nI7-m5Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Types of labels: Single column, binary values "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VVpDCY9-6BJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "0db7ecd9-9661-4ce0-ad17-499a0f134871"
      },
      "source": [
        "column_map = { v:k for k, v in enumerate(churn_df.columns)}\n",
        "column_map"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Churn': 20,\n",
              " 'Contract': 15,\n",
              " 'Dependents': 4,\n",
              " 'DeviceProtection': 11,\n",
              " 'InternetService': 8,\n",
              " 'MonthlyCharges': 18,\n",
              " 'MultipleLines': 7,\n",
              " 'OnlineBackup': 10,\n",
              " 'OnlineSecurity': 9,\n",
              " 'PaperlessBilling': 16,\n",
              " 'Partner': 3,\n",
              " 'PaymentMethod': 17,\n",
              " 'PhoneService': 6,\n",
              " 'SeniorCitizen': 2,\n",
              " 'StreamingMovies': 14,\n",
              " 'StreamingTV': 13,\n",
              " 'TechSupport': 12,\n",
              " 'TotalCharges': 19,\n",
              " 'customerID': 0,\n",
              " 'gender': 1,\n",
              " 'tenure': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y13Ysq133nQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numeric features - Standardized\n",
        "# Categorical features - One Hot Encoded\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSaPrDx6-1VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = [column_map[i] for i in ('tenure','MonthlyCharges', 'TotalCharges' )]\n",
        "categorical_feature = [column_map[i] for i in ('gender', 'SeniorCitizen', 'Partner', 'Dependents', \n",
        "                       'PhoneService', 'MultipleLines','InternetService',\n",
        "                       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
        "                       'PaperlessBilling', 'PaymentMethod') \n",
        "                      ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S11hqSF8__MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess = ColumnTransformer(\n",
        "    transformers = [\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_feature)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLuto48mAjd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_transform = preprocess.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VALOdNVJCq5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6a2261d-5a8a-4898-f148-27df6d4994db"
      },
      "source": [
        "X_transform.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfb8EDZ7GFuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4551cee9-b510-4db8-ed3d-87bb58b35ae1"
      },
      "source": [
        "X_transform[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.27744458, -1.16032292, -0.99261052,  1.        ,  0.        ,\n",
              "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
              "        0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "        0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
              "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "        0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "        0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "        0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obvus-HcInJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save preprocess for future\n",
        "\n",
        "import pickle\n",
        "pickle.dump(preprocess, open('/tmp/preprocess.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZU23Z1XWMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhCq-HfmOQOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "79b30084-71b0-4259-bd7a-9c7adc8aa85b"
      },
      "source": [
        "# Apply knn algorithm to predict\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "display = True\n",
        "acc_knn=[]\n",
        "n_neighbors = 3 # Hyper parameter\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  knn.fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  # Compute the nearest neighbor accuracy on the embedded test set\n",
        "  acc_knn.append(knn.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \") \n",
        "    print(confusion_matrix(knn.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_knn = np.array(acc_knn)\n",
        "print(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[879 174]\n",
            " [156 200]]\n",
            " Knn with neighbors=3, accuracy=0.753144790091921, 0.00855214427300203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP5WxOsXWEiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "4dac927d-ecda-4bac-d00a-a6c958a36159"
      },
      "source": [
        "display = True\n",
        "acc_knn = []\n",
        "n_neighbors = 10 # Hyper parameter\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  knn.fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  # Compute the nearest neighbor accuracy on the embedded test set\n",
        "  acc_knn.append(knn.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(knn.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "\"\"\"\n",
        "Not much change \n",
        "\"\"\"\n",
        "acc_knn = np.array(acc_knn)\n",
        "print(\" Knn with neighbors={0}, accuracy={1},{2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[948 201]\n",
            " [ 87 173]]\n",
            " Knn with neighbors=10, accuracy=0.7827913459166702,0.008589727204208577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_9IP6d1Pz9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "daa62dc1-20db-480a-8818-d182eb2b6640"
      },
      "source": [
        "# Apply SVM algo\n",
        "from sklearn import svm\n",
        "acc_svm = []\n",
        "display = True\n",
        "clf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_svm.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "    \n",
        "acc_svm = np.array(acc_svm)\n",
        "print(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[974 246]\n",
            " [ 61 128]]\n",
            " svm with kernel=rbf, accuracy=0.7803500191428542,0.008256413951220698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhSR1YsDfUfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "cf16f9a1-4665-4e96-de2e-9ef9c4d278f3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "acc_rf = []\n",
        "display = True\n",
        "clf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_rf.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "    \n",
        "acc_rf = np.array(acc_rf)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[953 187]\n",
            " [ 82 187]]\n",
            " RF with n_estimators=500, accuracy=10,0.7969891594445899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv6FaEgixi6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "726d1dee-68d4-47f8-e95e-c33c539f80ce"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "acc_et = []\n",
        "display = True\n",
        "clf = ExtraTreesClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_et.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_et = np.array(acc_et)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_et.mean(), acc_et.std()))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[939 188]\n",
            " [ 96 186]]\n",
            " RF with n_estimators=500, accuracy=10,0.7857014733692381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR2wM_ewmTJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2ff6623a-e294-4103-f44e-228ff9406898"
      },
      "source": [
        "import xgboost as xgb\n",
        "display = True\n",
        "acc_xgb = []\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf = xgb.XGBClassifier().fit(X_transform[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_xgb.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "acc_xgb = np.array(acc_xgb)\n",
        "print(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[953 179]\n",
            " [ 82 195]]\n",
            " XGB with accuracy=0.8046147342976893,0.008685475971088683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4MZG-mX0tdm",
        "colab_type": "text"
      },
      "source": [
        "##Stacking Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0tqGg7Es8RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "skb = SelectKBest(mutual_info_classif, k=2)\n",
        "nca = NeighborhoodComponentsAnalysis(n_components=3, random_state=42)\n",
        "lda = LinearDiscriminantAnalysis(n_components=3)\n",
        "clf = LassoCV(cv=4)\n",
        "sfm = SelectFromModel(clf, threshold=0.25)\n",
        "\n",
        "union = FeatureUnion(\n",
        "    [\n",
        "        (\"pca\", pca),\n",
        "        (\"skb\", skb),\n",
        "        (\"nca\", nca),\n",
        "        (\"lda\", lda),\n",
        "        (\"sfm\", sfm)\n",
        "        \n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mz50lNz451r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "e2835bab-2faa-4b6a-9481-4fd0b6e30f5a"
      },
      "source": [
        "union.fit(X_transform, LabelEncoder().fit_transform(y))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(46, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeatureUnion(n_jobs=None,\n",
              "             transformer_list=[('pca',\n",
              "                                PCA(copy=True, iterated_power='auto',\n",
              "                                    n_components=5, random_state=None,\n",
              "                                    svd_solver='auto', tol=0.0, whiten=False)),\n",
              "                               ('skb',\n",
              "                                SelectKBest(k=2,\n",
              "                                            score_func=<function mutual_info_classif at 0x7fa082430730>)),\n",
              "                               ('nca',\n",
              "                                NeighborhoodComponentsAnalysis(callback=None,\n",
              "                                                               init='auto',\n",
              "                                                               max_iter=50,\n",
              "                                                               n_components=3,\n",
              "                                                               random_state=42,\n",
              "                                                               t...\n",
              "                               ('sfm',\n",
              "                                SelectFromModel(estimator=LassoCV(alphas=None,\n",
              "                                                                  copy_X=True,\n",
              "                                                                  cv=4,\n",
              "                                                                  eps=0.001,\n",
              "                                                                  fit_intercept=True,\n",
              "                                                                  max_iter=1000,\n",
              "                                                                  n_alphas=100,\n",
              "                                                                  n_jobs=None,\n",
              "                                                                  normalize=False,\n",
              "                                                                  positive=False,\n",
              "                                                                  precompute='auto',\n",
              "                                                                  random_state=None,\n",
              "                                                                  selection='cyclic',\n",
              "                                                                  tol=0.0001,\n",
              "                                                                  verbose=False),\n",
              "                                                max_features=None, norm_order=1,\n",
              "                                                prefit=False,\n",
              "                                                threshold=0.25))],\n",
              "             transformer_weights=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v__sccD55itn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "daa907d2-de8c-4346-b414-4935e56f1f08"
      },
      "source": [
        "X_feature = union.transform(X_transform)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:79: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOOkDzC7--s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6f67a0a-3bed-4dfd-8299-996d4586db44"
      },
      "source": [
        "X_feature.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ERNq9BcXYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "62fd4e00-2ceb-4659-cb18-5a18b7228317"
      },
      "source": [
        "X_feature[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.22215532e+00, -1.71455714e+00,  1.45403482e+00,  4.30145069e-01,\n",
              "        7.09163700e-01, -1.27744458e+00,  1.00000000e+00, -5.83864377e+01,\n",
              "       -6.05901584e+02, -2.01974149e+01,  1.02332910e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6_JN2h5cBLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save union for future\n",
        "\n",
        "import pickle\n",
        "pickle.dump(union, open('/tmp/union.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbdymdeBoxyx",
        "colab_type": "text"
      },
      "source": [
        "## Apply Model and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_jgigLQZybM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8ab4e37b-fa69-4e8a-dfc0-02df293fff98"
      },
      "source": [
        "# Apply knn algorithm to predict\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "display = True\n",
        "acc_knn=[]\n",
        "n_neighbors = 3 # Hyper parameter\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  knn.fit(X_feature[train_indices, :], y[train_indices])\n",
        "  \n",
        "  # Compute the nearest neighbor accuracy on the embedded test set\n",
        "  acc_knn.append(knn.score(X_feature[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \") \n",
        "    print(confusion_matrix(knn.predict(X_feature[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_knn = np.array(acc_knn)\n",
        "print(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[910 174]\n",
            " [125 200]]\n",
            " Knn with neighbors=3, accuracy=0.7814700703115265, 0.0071675415187152655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npj3xz-1hbnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c262e6db-72b1-4e6e-8691-145a6942cee8"
      },
      "source": [
        "# Apply SVM algo\n",
        "from sklearn import svm\n",
        "acc_svm = []\n",
        "display = True\n",
        "clf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_feature[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_svm.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "        \n",
        "    \n",
        "acc_svm = np.array(acc_svm)\n",
        "print(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[1026  358]\n",
            " [   9   16]]\n",
            " svm with kernel=rbf, accuracy=0.7395315826827538,0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13RWWRajEls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "501fa245-9115-407c-8a35-e047ad125bf2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "acc_rf = []\n",
        "display = True\n",
        "clf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_feature[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_rf.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "    \n",
        "acc_rf = np.array(acc_rf)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[937 171]\n",
            " [ 98 203]]\n",
            " RF with n_estimators=500, accuracy=3,0.7973730354614439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbKa6KJMjRI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "fd355112-feed-49e3-a8f8-f2eb9ac3ae1b"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "acc_et = []\n",
        "display = True\n",
        "clf = ExtraTreesClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_feature[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_et.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_et = np.array(acc_et)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_et.mean(), acc_et.std()))\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[934 177]\n",
            " [101 197]]\n",
            " RF with n_estimators=500, accuracy=3,0.7940642725740656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH7wFcTjjogB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7f6b882a-70c7-4b92-e0e1-2cc0a6892814"
      },
      "source": [
        "import xgboost as xgb\n",
        "display = True\n",
        "acc_xgb = []\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf = xgb.XGBClassifier().fit(X_feature[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_xgb.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "acc_xgb = np.array(acc_xgb)\n",
        "print(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[950 174]\n",
            " [ 85 200]]\n",
            " XGB with accuracy=0.8074402397421794,0.008516071914349499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2IQACFgkXoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_merged = np.hstack((X_transform, X_feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSwQUsVlacB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc468c2b-e0c9-47e7-e6d2-5514647663ee"
      },
      "source": [
        "X_merged.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 57)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROHKHBuCldkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c9dbb96a-3a28-4eb6-fe02-20cdc1d393c8"
      },
      "source": [
        "# Apply SVM algo\n",
        "from sklearn import svm\n",
        "acc_svm = []\n",
        "display = True\n",
        "clf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_merged[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_svm.append(clf.score(X_merged[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_merged[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "        \n",
        "    \n",
        "acc_svm = np.array(acc_svm)\n",
        "print(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[1026  358]\n",
            " [   9   16]]\n",
            " svm with kernel=rbf, accuracy=0.7379099332497,0.0025513383556078823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evkN8nWemWK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e764ef16-1a55-4d0f-9240-c5ff173d3ae0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "acc_rf = []\n",
        "display = True\n",
        "clf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_merged[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_rf.append(clf.score(X_merged[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_merged[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "     \n",
        "  \n",
        "acc_rf = np.array(acc_rf)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[942 181]\n",
            " [ 93 193]]\n",
            " RF with n_estimators=500, accuracy=3,0.8055358410220014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoBxcn25vNk",
        "colab_type": "text"
      },
      "source": [
        "## Second Level of Feature  Preprocessing and Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IBWuSVC5ujr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = churn_df.values[:, :-1] # Not considering customer_id\n",
        "y = churn_df.values[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7i6d6jBIs4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c93fe9da-0527-4a92-dfe6-4a724975e3ff"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['7590-VHVEG', 'Female', 0, 'Yes', 'No', 1, 'No',\n",
              "       'No phone service', 'DSL', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
              "       'Month-to-month', 'Yes', 'Electronic check', 29.85, 29.85],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z83gWS6k57ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from statsmodels.distributions import ECDF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbRmC9NR8Elz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features_index = [column_map[i] for i in ('tenure','MonthlyCharges', 'TotalCharges' )]\n",
        "categorical_feature_name = ('gender', 'SeniorCitizen', 'Partner', 'Dependents', \n",
        "                       'PhoneService', 'MultipleLines','InternetService',\n",
        "                       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
        "                       'PaperlessBilling', 'PaymentMethod')\n",
        "categorical_feature_index = [column_map[i] for i in categorical_feature_name \n",
        "                      ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_lzFBcEJ51l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28133756-dc7f-45fa-a2b0-3dbed82c21d0"
      },
      "source": [
        "categorical_feature_index"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGNs0tUwLZZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a44fedbf-9570-424d-c62f-92bc3ea9b187"
      },
      "source": [
        "X[1, categorical_feature_index]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Male', 0, 'No', 'No', 'Yes', 'No', 'DSL', 'Yes', 'No', 'Yes',\n",
              "       'No', 'No', 'No', 'One year', 'No', 'Mailed check'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB3Zzj4j7yeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CounterEncoder(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, min_count=0, nan_value=-1, copy=True):\n",
        "    self.min_cnt = min_count\n",
        "    self.nans = nan_value\n",
        "    self.cp = copy\n",
        "    self.counts = {}\n",
        "    \n",
        "  def is_numpy(self, x):\n",
        "    return isinstance(x, np.ndarray)\n",
        "    \n",
        "  def fit(self, x):\n",
        "    self.counts = {}\n",
        "    if len(x.shape) == 1:\n",
        "      x = x.reshape(-1, 1)\n",
        "    ncols = x.shape[1]\n",
        "    is_np = self.is_numpy(x)\n",
        "    \n",
        "    for i in range(ncols):\n",
        "      if is_np:\n",
        "        cnt = dict(Counter(x[:, i]))\n",
        "      else:\n",
        "        cnt = x.iloc[:, i].value_counts().to_dict()\n",
        "        \n",
        "      if self.min_cnt > 0:\n",
        "        cnt = dict((k, self.nans if v < self.min else v ) for k, v in cnt.items())\n",
        "    \n",
        "      self.counts.update({i:cnt})\n",
        "    return self\n",
        "  \n",
        "  def fit_transform(self, x):\n",
        "    self.fit(x)\n",
        "    return self.transform(x)\n",
        "  \n",
        "  def transform(self, x):\n",
        "    if self.cp:\n",
        "      xm = x.copy()\n",
        "      \n",
        "    if len(xm.shape) == 1:\n",
        "      xm = xm.reshape(-1, 1)\n",
        "      \n",
        "    ncols = xm.shape[1]\n",
        "    is_np = self.is_numpy(xm)\n",
        "    \n",
        "    for i in range(ncols):\n",
        "      cnt = self.counts[i]\n",
        "      \n",
        "      if is_np:\n",
        "        k, v = np.array( list ( zip ( *sorted(cnt.items()))))\n",
        "        ix = np.digitize(xm[:, i], k, right=True)\n",
        "        xm[:, i] = v[ix]\n",
        "      else:\n",
        "        xm.iloc[:, i].replace(cnt, inplace=True)\n",
        "    return xm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAH8J2nv8TG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_counter = counter.fit_transform(X[:, categorical_feature_index])\n",
        "X_label = X.copy()\n",
        "for i in categorical_feature_index:\n",
        "  X_label[:, i] = LabelEncoder().fit(X[:, i]).transform(X[:, i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8UyFx0Y9Crw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = CounterEncoder()\n",
        "X_label_count = counter.fit_transform(X_label[:, categorical_feature_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmiZQVUGIKRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d4943abe-9af2-4709-843a-085490259bd4"
      },
      "source": [
        "X_label_count[:3, :]"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3488, 5901, 3402, 4933, 682, 682, 2421, 3498, 2429, 3095, 3473,\n",
              "        2810, 2785, 3875, 4171, 2365],\n",
              "       [3555, 5901, 3641, 4933, 6361, 3390, 2421, 2019, 3088, 2422, 3473,\n",
              "        2810, 2785, 1473, 2872, 1612],\n",
              "       [3555, 5901, 3641, 4933, 6361, 3390, 2421, 2019, 2429, 3095, 3473,\n",
              "        2810, 2785, 3875, 4171, 1612]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prsktDJoN6Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PercentileEncoder(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, apply_ppf=False, copy=True):\n",
        "    self.ppf = lambda x: norm.ppf(x * .998 + .001) if apply_ppf else x\n",
        "    self.cp = copy\n",
        "    self.ecdfs = {}\n",
        "    \n",
        "  def is_numpy(self, x):\n",
        "    return isinstance(x, np.ndarray)\n",
        "    \n",
        "  def fit(self, x):\n",
        "    self.ecdfs = {}\n",
        "    \n",
        "    if len(x.shape) == 1:\n",
        "      x = x.reshape(-1, 1)\n",
        "      \n",
        "    ncols = x.shape[1]\n",
        "    is_np = self.is_numpy(x)\n",
        "    \n",
        "    for i in range(ncols):\n",
        "      if is_np:\n",
        "        self.ecdfs.update({i: ECDF(x[:, i])})\n",
        "      else:\n",
        "        self.ecdfs.update({i: ECDF(x.iloc[:, i].values)})\n",
        "        \n",
        "    return self\n",
        "  \n",
        "  def fit_transform(self, x):\n",
        "    self.fit(x)\n",
        "    return self.transform(x)\n",
        "  \n",
        "  def transform(self, x):\n",
        "    \n",
        "    if self.cp:\n",
        "      xm = x.copy()\n",
        "      \n",
        "    if len(xm.shape) == 1:\n",
        "      xm = xm.reshape(-1, 1)\n",
        "      \n",
        "    ncols = xm.shape[1]  \n",
        "    is_np = self.is_numpy(xm)\n",
        "    \n",
        "    for i in range(ncols):\n",
        "      ecdf = self.ecdfs[i]\n",
        "      if is_np:\n",
        "        xm[:, i] = self.ppf(ecdf(xm[:, i]))\n",
        "      else:\n",
        "        xm.iloc[:, i] = self.ppf(ecdf(xm[:, i]))\n",
        "        \n",
        "    return xm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKNLQo62Qr5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = PercentileEncoder()\n",
        "\n",
        "X_percentile = p.fit_transform(X[:, numeric_features_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLnEgSjwRGVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e62e3fe4-2c79-49bf-9ab0-9a0999693ff8"
      },
      "source": [
        "X_percentile[:3, :]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08859860854749398, 0.23384921198352973, 0.030242794263808038],\n",
              "       [0.5543092432202187, 0.3941502200766719, 0.582564248189692],\n",
              "       [0.12239102655118558, 0.3553883288371433, 0.1211131620048275]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5avZLuWRVjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import check_X_y, check_array\n",
        "\n",
        "def is_numpy(x):\n",
        "    return isinstance(x, np.ndarray)\n",
        "  \n",
        "class LikelihoodEstimator(BaseEstimator):\n",
        "    def __init__(self, seed=0, alpha=0, noise=0, leave_one_out=False):\n",
        "        self.alpha = alpha\n",
        "        self.noise = noise\n",
        "        self.seed = seed\n",
        "        self.leave_one_out = leave_one_out\n",
        "        self.nclass = None\n",
        "        self.classes = None\n",
        "        self.class_priors = None\n",
        "        self.likelihoods = None\n",
        "        self.x_likelihoods = None\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        np.random.seed(self.seed)\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.reshape(-1, 1)\n",
        "\n",
        "        x, y = check_X_y(x, y)\n",
        "\n",
        "        self.classes = np.unique(y)\n",
        "        self.nclass = self.classes.shape[0]\n",
        "\n",
        "        ctab = pd.crosstab(y, list(x.T)).T.reset_index()\n",
        "\n",
        "        xdim = x.shape[1]\n",
        "        xcols = list(ctab.columns[:xdim])\n",
        "        ycols = list(ctab.columns[xdim:])\n",
        "\n",
        "        xtab = pd.DataFrame(x, columns=xcols)\n",
        "        xtab = xtab.merge(ctab, how='left', on=xcols)\n",
        "\n",
        "        self.class_priors = xtab[ycols].div(xtab[ycols].sum(axis=1), axis=0).mean().values\n",
        "\n",
        "        if self.leave_one_out:\n",
        "            xtab[ycols] -= pd.get_dummies(y)\n",
        "\n",
        "        xtab[ycols] = xtab[ycols].add(self.class_priors * self.alpha). \\\n",
        "            div(xtab[ycols].sum(axis=1) + self.alpha + 1E-15, axis=0)\n",
        "        if self.noise > 0:\n",
        "            xtab[ycols] = np.abs(xtab[ycols] + normal(0, scale=self.noise, size=xtab[ycols].shape))\n",
        "            xtab[ycols] = xtab[ycols].div(xtab[ycols].sum(axis=1), axis=0)\n",
        "        self.x_likelihoods = xtab[ycols].values\n",
        "\n",
        "        xtab_agg = xtab.groupby(xcols, as_index=False)[ycols].agg(['mean']).fillna(0)\n",
        "        xtab_agg.columns = xtab_agg.columns.get_level_values(1)\n",
        "\n",
        "        self.likelihoods = xtab_agg.T.ix['mean'].reset_index(drop=True).T.reset_index()\n",
        "        # self.likelihoods = xtab_agg.T.ix['mean'].reset_index(drop=True).to_dict('list')\n",
        "        # self.likelihoods_cov = xtab_agg.T.ix['std'].reset_index(drop=True).to_dict('list')\n",
        "        # self.likelihoods_cov = dict((k, np.diag(v)) for k, v in self.likelihoods_cov.items())\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _calc_likelihood(self, x):\n",
        "        return (x + self.class_priors * self.alpha) / (x.sum() + self.alpha)\n",
        "\n",
        "    def _get_likelihood(self, x, noise):\n",
        "        mean = self.likelihoods.get(x[0], self.class_priors)\n",
        "        cov = self.likelihoods_cov.get(x[0], np.diag(np.zeros((self.nclass,))))\n",
        "        if noise:\n",
        "            if isinstance(noise, float):\n",
        "                cov = np.diag(np.ones((self.nclass,)) * noise)\n",
        "            lh = np.abs(multivariate_normal(mean, cov))\n",
        "            return lh / lh.sum()\n",
        "        else:\n",
        "            return mean\n",
        "\n",
        "    def predict(self, x, noise=False, normalize=False):\n",
        "        if normalize:\n",
        "            return np.average(self.predict_proba(x, noise), axis=1, weights=self.classes)\n",
        "        else:\n",
        "            return np.dot(self.predict_proba(x, noise), self.classes)\n",
        "\n",
        "    def predict_proba(self, x, noise=False):\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.reshape(-1, 1)\n",
        "\n",
        "        x = check_array(x)\n",
        "\n",
        "        xx = pd.DataFrame(x, columns=self.likelihoods.columns[:-self.nclass])\n",
        "        xx = xx.merge(self.likelihoods, how='left')\n",
        "        xx.drop(xx.columns[:-self.nclass], axis=1, inplace=True)\n",
        "        xx.loc[xx.isnull().any(axis=1) | (xx == 0).all(axis=1), :] = self.class_priors\n",
        "\n",
        "        if noise:\n",
        "            np.random.seed(self.seed)\n",
        "            _noise = noise if isinstance(noise, float) else self.noise\n",
        "            if _noise > 1E-12:\n",
        "                xx = np.abs(xx + normal(0, scale=_noise, size=xx.shape))\n",
        "                xx = xx.div(xx.sum(axis=1), axis=0)\n",
        "\n",
        "        # return np.apply_along_axis(self._get_likelihood, 1, x, noise)\n",
        "        return xx.values\n",
        "\n",
        "class LikelihoodEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, seed=0, alpha=0, leave_one_out=False, noise=0):\n",
        "        self.alpha = alpha\n",
        "        self.noise = noise\n",
        "        self.seed = seed\n",
        "        self.leave_one_out = leave_one_out\n",
        "        self.nclass = None\n",
        "        self.estimators = []\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.reshape(-1, 1)\n",
        "        ncols = x.shape[1]\n",
        "        if not is_numpy(x):\n",
        "            x = np.array(x)\n",
        "\n",
        "        self.nclass = np.unique(y).shape[0]\n",
        "\n",
        "        for i in range(ncols):\n",
        "            self.estimators.append(LikelihoodEstimator(**self.get_params()).fit(x[:, i], y))\n",
        "        return self\n",
        "      \n",
        "    def fit_transform(self, x, y):\n",
        "        self.fit(x, y)\n",
        "        return self.transform(x)\n",
        "\n",
        "    def transform(self, x):\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.reshape(-1, 1)\n",
        "        ncols = x.shape[1]\n",
        "        if not is_numpy(x):\n",
        "            x = np.array(x)\n",
        "\n",
        "        likelihoods = None\n",
        "\n",
        "        for i in range(ncols):\n",
        "            lh = self.estimators[i].predict(x[:, i], noise=True).reshape(-1, 1)\n",
        "            # lh = self.estimators[i].predict_proba(x[:, i])\n",
        "            # if self.nclass <= 2:\n",
        "            #     lh = lh.T[1].reshape(-1, 1)\n",
        "            likelihoods = np.hstack((lh,)) if likelihoods is None else np.hstack((likelihoods, lh))\n",
        "        return likelihoods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BniBAXP0Sh0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_counter = counter.fit_transform(X[:, categorical_feature_index])\n",
        "X_cat = X.copy()\n",
        "for i in categorical_feature_index:\n",
        "  X_cat[:, i] = LabelEncoder().fit(X[:, i]).transform(X[:, i])\n",
        "  \n",
        "le = LikelihoodEncoder()\n",
        "X_likelihood = le.fit_transform(X_cat[:, 1:], LabelEncoder().fit_transform(y)) # # Not considering customer_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP3LY22hTPeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_feature_stacking = np.hstack([X_label_count, X_percentile, X_likelihood])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4l0hJDzom2B",
        "colab_type": "text"
      },
      "source": [
        "## Apply Model and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrdmfXAfUuBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "814bab64-2534-409e-ff96-d2eaa8578439"
      },
      "source": [
        "# Apply knn algorithm to predict\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "display = True\n",
        "acc_knn=[]\n",
        "n_neighbors = 3 # Hyper parameter\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  knn.fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "  \n",
        "  # Compute the nearest neighbor accuracy on the embedded test set\n",
        "  acc_knn.append(knn.score(X_feature_stacking[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \") \n",
        "    print(confusion_matrix(knn.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_knn = np.array(acc_knn)\n",
        "print(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[917 177]\n",
            " [118 197]]\n",
            " Knn with neighbors=3, accuracy=0.7809884270223454, 0.008618955990493584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwe6O2zUU591",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0dcf62b2-51e5-402e-cac8-ed88f6877956"
      },
      "source": [
        "# Apply Naive algorithm to predict\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "display = True\n",
        "acc_nb=[]\n",
        "n_neighbors = 3 # Hyper parameter\n",
        "nb = GaussianNB()\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  nb.fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "  \n",
        "  # Compute the nearest neighbor accuracy on the embedded test set\n",
        "  acc_nb.append(nb.score(X_feature_stacking[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \") \n",
        "    print(confusion_matrix(knn.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "  \n",
        "acc_nb = np.array(acc_nb)\n",
        "print(\" NB with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_nb.mean(), acc_nb.std()))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[945 135]\n",
            " [ 90 239]]\n",
            " NB with neighbors=3, accuracy=0.966435368528946, 0.005580538080268117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBF3dhPMWRh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "23a222ee-379e-415f-8241-b9ebd8568ca5"
      },
      "source": [
        "# Apply SVM algo\n",
        "from sklearn import svm\n",
        "acc_svm = []\n",
        "display = True\n",
        "clf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_svm.append(clf.score(X_feature_stacking[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "        \n",
        "    \n",
        "acc_svm = np.array(acc_svm)\n",
        "print(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n",
        "\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[1012  263]\n",
            " [  23  111]]\n",
            " svm with kernel=rbf, accuracy=0.8062766770426485,0.006095040881327082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4AI9tStXGQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f78ae487-2261-49a9-ce33-c52694574ce6"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "acc_rf = []\n",
        "display = True\n",
        "clf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf.fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_rf.append(clf.score(X_feature_stacking[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "     \n",
        "  \n",
        "acc_rf = np.array(acc_rf)\n",
        "print(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion metrics = \n",
            "[[1019   18]\n",
            " [  16  356]]\n",
            " RF with n_estimators=500, accuracy=3,0.9793555995748724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFAM4V7xfGjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "display = True\n",
        "acc_xgb = []\n",
        "\n",
        "for train_indices, test_indices in training_test_split:\n",
        "  clf = xgb.XGBClassifier().fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "  \n",
        "  acc_xgb.append(clf.score(X_feature_stacking[test_indices,:], y[test_indices]))\n",
        "  \n",
        "  if display:\n",
        "    print(\"confusion metrics = \")\n",
        "    print(confusion_matrix(clf.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n",
        "    display = False\n",
        "    \n",
        "acc_xgb = np.array(acc_xgb)\n",
        "print(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0c5N8HIpAmN",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search For RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otEm0yPhXiSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from time import time\n",
        "param_dist = {\n",
        "    \"n_estimators\": [120, 300, 500, 800, 1200],\n",
        "    \"max_depth\": [5, 8, 15, 25, 30, None],\n",
        "    \"max_features\": [\"log2\", \"sqrt\", None],\n",
        "    \"min_samples_split\": [2, 5, 10, 15, 100],\n",
        "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(clf, param_grid=param_dist, cv=5)\n",
        "start = time()\n",
        "grid_search.fit(X_feature_stacking[train_indices, :], y[train_indices])\n",
        "end = time()\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VnkF1pKcC38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "clf = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "y_pred_rf = clf.predict_proba(X_feature_stacking[test_indices,:])\n",
        "fpr_rf, tpr_rf, _ = roc_curve(LabelEncoder().fit_transform(y[test_indices]), y_pred_rf[:, 1])\n",
        "\n",
        "auc = roc_auc_score(LabelEncoder().fit_transform(y[test_indices]), y_pred_rf[:, 1])\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rf, tpr_rf, label='RF AUC {}'.format(np.round(auc, 3)))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}