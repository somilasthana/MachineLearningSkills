{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL-UnStacking tranforming rental data into high dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ETL process reads NSW Rental Bonds information publically available and does following\n",
    "1. Cleans the Dataset by removing unwanted columns.\n",
    "2. Removes rows which are NULL\n",
    "3. For Categorical Fields like PremisesDwellingType and Premises_Suburb converts empty fields as UNKNOWN\n",
    "4. Data cleaning, convert timestamp field as epoch or specific data types\n",
    "5. Add new columns like MonthName, DayStatus (Early if it within 10 days or Late if it was after 10 days)\n",
    "6. Added Fields like SchoolAdmit ie months when School Admission starts which drives Rental and Occpancy\n",
    "7. However, instead of just storing the cleanized data for further analyzes. It does following\n",
    "   7.1 Identifies Time Dimension, Categorical Variables, Response Variables and Contributing Factors.\n",
    "   7.2 For Each Categorical Variables ie (\"PremisesDwellingType\", \"NumberBedrooms\", \"Premises_Postcode\", \"Premises_Suburb\") we pin the following :  \n",
    "       a. Time Dimension (Time when the tenancy and bond application was lodged)\n",
    "       b. Contributing Factors (Was it a holiday season or school admission period which triggered this process )\n",
    "       c. Response Variable e.g for \"BondAmount\" it is amount Bond deposit.\n",
    "8. Eventually all these unstacked data is stored back\n",
    "\n",
    "This converts the dataset into a high dimensions so that analytical system can easily analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsw_rental_history = spark.read.format(\n",
    "   \"com.databricks.spark.csv\").option(\n",
    "   \"header\", \"true\").option(\n",
    "   \"inferSchema\", \"true\").load(\n",
    "   's3://nsw_services/dept_finance/nsw_rental/fa13-2016-17.parquet')\n",
    "\n",
    "df_rent = nsw_rental_history.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DateTenancyCommenced: string (nullable = true)\n",
      " |-- DateLodgement: string (nullable = true)\n",
      " |-- BondAmount: string (nullable = true)\n",
      " |-- PremisesWeeklyRent: string (nullable = true)\n",
      " |-- PremisesDwellingType: string (nullable = true)\n",
      " |-- NumberBedrooms: string (nullable = true)\n",
      " |-- Premises_Postcode: string (nullable = true)\n",
      " |-- Premises_Suburb: string (nullable = true)\n",
      " |-- Released: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rent.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Released|\n",
      "+--------+\n",
      "|    null|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rent.select(\"Released\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent = df_rent.drop(\"Released\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PremisesDwellingType='F', count=365256),\n",
       " Row(PremisesDwellingType='T', count=69664),\n",
       " Row(PremisesDwellingType='B', count=83),\n",
       " Row(PremisesDwellingType='O', count=26533),\n",
       " Row(PremisesDwellingType='C', count=1),\n",
       " Row(PremisesDwellingType='S', count=7),\n",
       " Row(PremisesDwellingType=' ', count=1935),\n",
       " Row(PremisesDwellingType='NULL', count=169715),\n",
       " Row(PremisesDwellingType='H', count=280548)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent.groupby(\"PremisesDwellingType\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF\n",
    "clean_f = udf(lambda x: float(x[1:].replace(\",\",\"\")), FloatType())\n",
    "unk_f = udf(lambda x: 'Unk' if len(x.strip()) == 0 else x)\n",
    "epoch_f = udf(lambda x: int(datetime.strptime(x,\"%d/%m/%Y\").strftime(\"%s\")), LongType())\n",
    "int_f = udf(lambda x: int(x), IntegerType())\n",
    "month_f = udf(lambda x: datetime.fromtimestamp(x).strftime(\"%b\"))\n",
    "day_f = udf(lambda x: \"Early\" if datetime.fromtimestamp(x).strftime(\"%d\")[0] == \"0\" else \"Late\")\n",
    "admit_f = udf(lambda x: 1 if datetime.fromtimestamp(x).strftime(\"%m\") in [\"11\", \"12\", \"01\", \"02\", \"03\"] else 0, IntegerType() ) \n",
    "holiday_f = udf(lambda x: 1 if datetime.fromtimestamp(x).strftime(\"%m\") in [\"11\", \"12\"] else 0, IntegerType() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent = df_rent.where((df_rent.DateTenancyCommenced != \"NULL\") & \n",
    "                        (df_rent.DateLodgement != \"NULL\") & (df_rent.BondAmount != \"NULL\") &\n",
    "                        (df_rent.PremisesWeeklyRent != \"NULL\") & (df_rent.PremisesDwellingType != \"NULL\") &\n",
    "                        (df_rent.NumberBedrooms != \"NULL\") & \n",
    "                        (df_rent.Premises_Postcode != \"NULL\") &\n",
    "                        (df_rent.Premises_Suburb != \"NULL\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent = df_rent.withColumn(\"BondAmount\", clean_f(df_rent.BondAmount))\\\n",
    "                 .withColumn(\"PremisesWeeklyRent\", clean_f(df_rent.PremisesWeeklyRent))\\\n",
    "                 .withColumn(\"Premises_Postcode\", int_f(df_rent.Premises_Postcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent = df_rent.withColumn(\"NumberBedrooms\", int_f(df_rent.NumberBedrooms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent = df_rent.withColumn(\"DateTenancyCommenced\", epoch_f(df_rent.DateTenancyCommenced))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"DateLodgement\", epoch_f(df_rent.DateLodgement))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"LengthOccupancy\", (df_rent.DateLodgement - df_rent.DateTenancyCommenced))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"MonthName\", month_f(df_rent.DateLodgement))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"DayStatus\", day_f(df_rent.DateLodgement))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"SchoolAdmit\", admit_f(df_rent.DateLodgement))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"Holiday\", holiday_f(df_rent.DateLodgement))\n",
    "\n",
    "df_rent = df_rent.withColumn(\"PremisesDwellingType\", unk_f(df_rent.PremisesDwellingType)).withColumn(\"Premises_Suburb\", unk_f(df_rent.Premises_Suburb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DateTenancyCommenced: long (nullable = true)\n",
      " |-- DateLodgement: long (nullable = true)\n",
      " |-- BondAmount: float (nullable = true)\n",
      " |-- PremisesWeeklyRent: float (nullable = true)\n",
      " |-- PremisesDwellingType: string (nullable = true)\n",
      " |-- NumberBedrooms: integer (nullable = true)\n",
      " |-- Premises_Postcode: integer (nullable = true)\n",
      " |-- Premises_Suburb: string (nullable = true)\n",
      " |-- LengthOccupancy: long (nullable = true)\n",
      " |-- MonthName: string (nullable = true)\n",
      " |-- DayStatus: string (nullable = true)\n",
      " |-- SchoolAdmit: integer (nullable = true)\n",
      " |-- Holiday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rent.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------+------------------+--------------------+--------------+-----------------+--------------------+---------------+---------+---------+-----------+-------+\n",
      "|DateTenancyCommenced|DateLodgement|BondAmount|PremisesWeeklyRent|PremisesDwellingType|NumberBedrooms|Premises_Postcode|     Premises_Suburb|LengthOccupancy|MonthName|DayStatus|SchoolAdmit|Holiday|\n",
      "+--------------------+-------------+----------+------------------+--------------------+--------------+-----------------+--------------------+---------------+---------+---------+-----------+-------+\n",
      "|          1369008000|   1371427200|    1920.0|             480.0|                   H|             4|             2489|    POTTSVILLE BEACH|        2419200|      Jun|     Late|          0|      0|\n",
      "|          1369180800|   1371427200|    2080.0|             520.0|                   H|             3|             2487|           CASUARINA|        2246400|      Jun|     Late|          0|      0|\n",
      "|          1369267200|   1371427200|    1640.0|             410.0|                   T|             3|             2489|    POTTSVILLE BEACH|        2160000|      Jun|     Late|          0|      0|\n",
      "|          1369180800|   1371427200|    2400.0|             600.0|                   H|             4|             2488|      CABARITA BEACH|        2246400|      Jun|     Late|          0|      0|\n",
      "|          1371168000|   1371427200|    1560.0|             390.0|                   O|             2|             2145|SOUTH WENTWORTHVILLE|         259200|      Jun|     Late|          0|      0|\n",
      "|          1370390400|   1371427200|    1720.0|             430.0|                   F|             2|             2151|    NORTH PARRAMATTA|        1036800|      Jun|     Late|          0|      0|\n",
      "|          1370390400|   1371427200|    1460.0|             365.0|                   F|             3|             2323|             METFORD|        1036800|      Jun|     Late|          0|      0|\n",
      "|          1371168000|   1371427200|    1400.0|             350.0|                   H|             3|             2320|          RUTHERFORD|         259200|      Jun|     Late|          0|      0|\n",
      "|          1369785600|   1371427200|    1600.0|             400.0|                   H|             4|             2320|    BOLWARRA HEIGHTS|        1641600|      Jun|     Late|          0|      0|\n",
      "|          1370563200|   1371427200|    1580.0|             395.0|                   H|             4|             2321|  GILLIESTON HEIGHTS|         864000|      Jun|     Late|          0|      0|\n",
      "+--------------------+-------------+----------+------------------+--------------------+--------------+-----------------+--------------------+---------------+---------+---------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rent.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PremisesDwellingType='F', count=313463),\n",
       " Row(PremisesDwellingType='Unk', count=582),\n",
       " Row(PremisesDwellingType='T', count=62793),\n",
       " Row(PremisesDwellingType='B', count=1),\n",
       " Row(PremisesDwellingType='O', count=19777),\n",
       " Row(PremisesDwellingType='C', count=1),\n",
       " Row(PremisesDwellingType='S', count=7),\n",
       " Row(PremisesDwellingType='H', count=245400)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rent.groupby(\"PremisesDwellingType\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\"PremisesDwellingType\", \"NumberBedrooms\", \"Premises_Postcode\", \"Premises_Suburb\"]\n",
    "time_vars = [\"DateTenancyCommenced\", \"DateLodgement\"]\n",
    "contrib_vars = [\"MonthName\", \"DayStatus\", \"SchoolAdmit\"]\n",
    "response_vars = [\"BondAmount\", \"PremisesWeeklyRent\" , \"LengthOccupancy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoints(cat, df_rent, interested_coln):\n",
    "    hmap_df = {}\n",
    "    df_dwelling_ = df_rent.groupBy(cat).agg(*[f.collect_list(c).alias(c) for c in interested_coln])\n",
    "    for c in interested_coln:\n",
    "        print(\"processing ...\" + c)\n",
    "        df_dwelling_1 = df_dwelling_.select(c, cat).withColumn(c, f.explode(c)).withColumn(\"id\", f.monotonically_increasing_id())\n",
    "        hmap_df.setdefault(c, df_dwelling_1)\n",
    "    \n",
    "    df_dwell = None\n",
    "    for c in hmap_df:\n",
    "        if df_dwell == None:\n",
    "            df_dwell = hmap_df[c]\n",
    "            continue\n",
    "        df_dwell = df_dwell.join(hmap_df[c].drop(cat), \"id\", \"outer\")\n",
    "        \n",
    "    \n",
    "    df_dwell = df_dwell.withColumn(\"FactorName\", f.lit(cat)).withColumnRenamed(cat, \"FactorValue\")\n",
    "    return df_dwell\n",
    "\n",
    "def response(cat, cresp, df_rent, df_dwell):\n",
    "    df_dwelling_ = df_rent.groupBy(cat).agg(f.collect_list(cresp).alias(cresp))\n",
    "    df_dwelling_1 = df_dwelling_.select(cresp).withColumn(cresp, f.explode(cresp)).withColumn(\"id\", f.monotonically_increasing_id())\n",
    "    df_dwell_1 = df_dwell.join(df_dwelling_1, \"id\", \"outer\")\n",
    "    df_dwell_1 = df_dwell_1.withColumn(\"ResponseName\", f.lit(cresp)).withColumnRenamed(cresp, \"ResponseValue\")\n",
    "    \n",
    "    return df_dwell_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ...DateTenancyCommenced\n",
      "processing ...DateLodgement\n",
      "processing ...MonthName\n",
      "processing ...DayStatus\n",
      "processing ...SchoolAdmit\n"
     ]
    }
   ],
   "source": [
    "df_dwell = datapoints(\"PremisesDwellingType\", df_rent, \n",
    "                      [\"DateTenancyCommenced\", \"DateLodgement\", \"MonthName\", \"DayStatus\", \"SchoolAdmit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+\n",
      "|          id|DateTenancyCommenced|FactorValue|DateLodgement|MonthName|DayStatus|SchoolAdmit|          FactorName|\n",
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+\n",
      "|171798692310|          1370649600|          F|   1371513600|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798692537|          1371254400|          F|   1371513600|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798692967|          1369958400|          F|   1371686400|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798693847|          1370649600|          F|   1372032000|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798693936|          1371254400|          F|   1372118400|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798694097|          1371859200|          F|   1372118400|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798694199|          1371081600|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798694276|          1371254400|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798694312|          1371254400|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|\n",
      "|171798694337|          1372032000|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|\n",
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dwell.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+-------------+------------+\n",
      "|          id|DateTenancyCommenced|FactorValue|DateLodgement|MonthName|DayStatus|SchoolAdmit|          FactorName|ResponseValue|ResponseName|\n",
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+-------------+------------+\n",
      "|171798692310|          1370649600|          F|   1371513600|      Jun|     Late|          0|PremisesDwellingType|       2400.0|  BondAmount|\n",
      "|171798692537|          1371254400|          F|   1371513600|      Jun|     Late|          0|PremisesDwellingType|       1040.0|  BondAmount|\n",
      "|171798692967|          1369958400|          F|   1371686400|      Jun|     Late|          0|PremisesDwellingType|       1120.0|  BondAmount|\n",
      "|171798693847|          1370649600|          F|   1372032000|      Jun|     Late|          0|PremisesDwellingType|       1940.0|  BondAmount|\n",
      "|171798693936|          1371254400|          F|   1372118400|      Jun|     Late|          0|PremisesDwellingType|       1840.0|  BondAmount|\n",
      "|171798694097|          1371859200|          F|   1372118400|      Jun|     Late|          0|PremisesDwellingType|       1400.0|  BondAmount|\n",
      "|171798694199|          1371081600|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|       1520.0|  BondAmount|\n",
      "|171798694276|          1371254400|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|       2440.0|  BondAmount|\n",
      "|171798694312|          1371254400|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|       2160.0|  BondAmount|\n",
      "|171798694337|          1372032000|          F|   1372204800|      Jun|     Late|          0|PremisesDwellingType|       2260.0|  BondAmount|\n",
      "+------------+--------------------+-----------+-------------+---------+---------+-----------+--------------------+-------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dwell_bond = response(\"PremisesDwellingType\", \"BondAmount\", df_rent, df_dwell)\n",
    "df_dwell_bond.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ...DateTenancyCommenced\n",
      "processing ...DateLodgement\n",
      "processing ...MonthName\n",
      "processing ...DayStatus\n",
      "processing ...SchoolAdmit\n",
      "processing ...DateTenancyCommenced\n",
      "processing ...DateLodgement\n",
      "processing ...MonthName\n",
      "processing ...DayStatus\n",
      "processing ...SchoolAdmit\n",
      "processing ...DateTenancyCommenced\n",
      "processing ...DateLodgement\n",
      "processing ...MonthName\n",
      "processing ...DayStatus\n",
      "processing ...SchoolAdmit\n",
      "processing ...DateTenancyCommenced\n",
      "processing ...DateLodgement\n",
      "processing ...MonthName\n",
      "processing ...DayStatus\n",
      "processing ...SchoolAdmit\n"
     ]
    }
   ],
   "source": [
    "stack_df_rent  = {}\n",
    "keep_coln = [\"DateTenancyCommenced\", \"DateLodgement\", \"MonthName\", \"DayStatus\", \"SchoolAdmit\"]\n",
    "for c in [\"PremisesDwellingType\", \"NumberBedrooms\", \"Premises_Postcode\", \"Premises_Suburb\"]:\n",
    "    df_dwell = datapoints(c, df_rent, keep_coln)\n",
    "    df_rent_resp_full = None\n",
    "    for r in [\"BondAmount\", \"PremisesWeeklyRent\" , \"LengthOccupancy\"]:\n",
    "        df_rent_resp = response(c, r, df_rent, df_dwell)\n",
    "        if df_rent_resp_full == None:\n",
    "            df_rent_resp_full = df_rent_resp\n",
    "        else:\n",
    "            df_rent_resp_full = df_rent_resp_full.union(df_rent_resp)\n",
    "    stack_df_rent.setdefault(c, df_rent_resp_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_name in stack_df_rent:\n",
    "    stack_df_rent[cat_name] = stack_df_rent[cat_name].drop(\"id\")\n",
    "    glue_df_rent_frame = DynamicFrame.fromDF(stack_df_rent[cat_name], glueContext, \"nested\")\n",
    "    glueContext.write_dynamic_frame.from_options(\n",
    "       frame = glue_df_rent_frame,\n",
    "       connection_type = \"s3\",\n",
    "       connection_options = {\"path\": \"s3://etl-rental/\"+cat_name+\"/\" + cat_name+\"_\"+\"rental_parquet\"},\n",
    "       format = \"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
